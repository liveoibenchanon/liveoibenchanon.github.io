Model,Contest Count,Total Tasks,Total Score,Total Included Score,Relative Score (%),Avg Tests Passed (%),Pass Rate (%),Gold Medals,Silver Medals,Bronze Medals,Total Medals,Avg Human Percentile,Competition Rank
gpt-5,2,12,343.0,343.0,28.584999999999997,43.215,16.669999999999998,0,0,1,1,44.28776511994072,1
gemini-2.5-pro,2,12,294.0,294.0,24.5,46.295,0.0,0,0,1,1,36.77178845975734,2
grok-4-fast-reasoning,2,12,317.0,317.0,26.415000000000003,46.685,8.334999999999999,0,0,0,0,38.98073538946004,3
gpt-oss-120b-high,2,12,295.0,295.0,24.58,40.755,16.669999999999998,0,0,0,0,34.51421691210521,3
seed-oss_-1,2,12,247.0,247.0,20.58,38.335,0.0,0,0,0,0,28.62137630823377,4
claude-sonnet-4.5,2,12,208.0,208.0,17.33,39.98,0.0,0,0,0,0,24.55543206446235,6
gpt-o3-mini-high,2,12,179.0,179.0,14.920000000000002,24.315,0.0,0,0,0,0,20.3551912568306,8
gemini-2.5-flash,2,12,175.0,175.0,14.585,30.294999999999998,0.0,0,0,0,0,18.475039362785957,9
claude-haiku-4.5,2,12,165.0,165.0,13.75,33.044999999999995,0.0,0,0,0,0,18.820042604427154,9
gpt-oss-120b-medium,2,12,151.0,151.0,12.579999999999998,28.109999999999996,0.0,0,0,0,0,14.920811336482355,10
gpt-oss-120b_sp1,2,12,144.0,144.0,12.0,26.835000000000004,0.0,0,0,0,0,14.237751227192739,11
gpt-oss-120b_sp2,2,12,139.0,139.0,11.585,24.46,0.0,0,0,0,0,13.714457719736965,12
deepseek-reasoner,2,12,133.0,133.0,11.085,27.220000000000006,0.0,0,0,0,0,11.954709641567103,12
OlympicCoder-32B,2,12,133.0,133.0,11.084999999999999,21.905,0.0,0,0,0,0,13.144855052329351,14
gpt-oss-20b-low,2,12,129.0,129.0,10.75,21.055,0.0,0,0,0,0,13.008243030471426,13
Qwen3-14B,2,12,125.0,125.0,10.415000000000001,22.57,0.0,0,0,0,0,12.00101880151894,16
gpt-oss-120b_sp3,2,12,124.0,124.0,10.334999999999999,22.96,0.0,0,0,0,0,12.00101880151894,17
gpt-oss-20b-high,2,12,128.0,128.0,10.665000000000001,24.370000000000005,0.0,0,0,0,0,11.792627581735669,15
gpt-oss-120b-low,2,12,122.0,122.0,10.165000000000001,21.475,0.0,0,0,0,0,11.915346855608039,17
gpt-oss-20b-medium,2,12,129.0,129.0,10.75,24.115000000000002,0.0,0,0,0,0,12.075113457441883,14
Qwen3-30B-Non-Thinking,2,12,111.0,111.0,9.25,18.740000000000002,0.0,0,0,0,0,12.491895897008428,18
gpt-oss-120b_sp4,2,12,108.0,108.0,9.0,17.955000000000002,0.0,0,0,0,0,9.514216912105214,22
Qwen3-8B,2,12,105.0,105.0,8.75,17.99,0.0,0,0,0,0,8.949245160692785,19
gpt-4.1,2,12,74.0,74.0,6.165,15.659999999999998,0.0,0,0,0,0,7.407150134296564,24
deepseek-chat,2,12,99.0,99.0,8.25,19.325,0.0,0,0,0,0,11.22997128832083,20
DeepSeek-R1-Distill-Llama-70B,2,12,75.0,75.0,6.25,20.97,0.0,0,0,0,0,5.533944614244698,23
Qwen3-14B-Non-Thinking,2,12,61.0,61.0,5.085,12.490000000000002,0.0,0,0,0,0,7.006575900713161,26
Mistral-Large-Instruct-2411,2,12,66.0,66.0,5.5,14.280000000000001,0.0,0,0,0,0,7.712790589978698,25
OpenCodeReasoning-Nemotron-32B-IOI,2,12,52.0,52.0,4.335,9.965,0.0,0,0,0,0,6.88385662684079,29
Qwen3-4B,2,12,50.0,50.0,4.165,12.485000000000001,0.0,0,0,0,0,3.7255719181254054,27
Qwen3-32B-Non-Thinking,2,12,44.0,44.0,3.67,10.975,0.0,0,0,0,0,4.600815041215153,30
QwQ-32B,2,12,92.0,92.0,7.665,14.734999999999998,0.0,0,0,0,0,10.9521163286098,21
Qwen3-8B-Non-Thinking,2,12,42.0,42.0,3.5,8.235000000000001,0.0,0,0,0,0,3.4523478744095586,31
Llama-4-Scout,2,12,34.0,34.0,2.83,10.32,0.0,0,0,0,0,2.905899786977864,33
Qwen2.5-Coder-14B-Instruct,2,12,25.0,25.0,2.085,10.13,0.0,0,0,0,0,2.905899786977864,36
OlympicCoder-7B,2,12,30.0,30.0,2.5,6.755,0.0,0,0,0,0,3.621376308233769,36
Mistral-Small-3.1-24B-2503,2,12,22.0,22.0,1.835,6.890000000000001,0.0,0,0,0,0,2.769287765119941,39
Qwen3-4B-Non-Thinking,2,12,22.0,22.0,1.835,6.245,0.0,0,0,0,0,2.769287765119941,41
DeepSeek-Coder-V2-Lite-Instruct,2,12,22.0,22.0,1.835,7.6,0.0,0,0,0,0,2.769287765119941,40
Qwen3-32B,2,12,192.0,192.0,16.0,30.509999999999998,0.0,0,0,0,0,21.732888765397796,7
Qwen2.5-Coder-32B-Instruct,2,12,76.0,76.0,6.330000000000001,18.029999999999998,0.0,0,0,0,0,7.986014633694545,22
Qwen2.5-Coder-7B-Instruct,2,12,12.0,12.0,1.0,5.5600000000000005,0.0,0,0,0,0,2.222839677688247,43
Llama-3.1-8B-Instruct,2,12,12.0,12.0,1.0,5.6899999999999995,0.0,0,0,0,0,2.222839677688247,44
DeepSeek-R1-Distill-Qwen-14B,2,12,25.0,25.0,2.08,6.99,0.0,0,0,0,0,2.632675743262017,38
DeepSeek-R1-Distill-Qwen-32B,2,12,40.0,40.0,3.3349999999999995,9.82,0.0,0,0,0,0,3.8946003519496157,32
DeepSeek-R1-Distill-Qwen-7B,2,12,0.0,0.0,0.0,0.0,0.0,0,0,0,0,1.6763915902565527,46
DeepSeek-R1-Distill-Llama-8B,2,12,0.0,0.0,0.0,1.755,0.0,0,0,0,0,1.6763915902565527,47
Codestral-22B-v0.1,2,12,0.0,0.0,0.0,1.6649999999999998,0.0,0,0,0,0,1.6763915902565527,48
