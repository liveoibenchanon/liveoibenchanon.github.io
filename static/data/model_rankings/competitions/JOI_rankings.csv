Model,Contest Count,Total Tasks,Total Score,Total Included Score,Relative Score (%),Avg Tests Passed (%),Pass Rate (%),Gold Medals,Silver Medals,Bronze Medals,Total Medals,Avg Human Percentile,Competition Rank
gpt-5,7,42,2072.0,2072.0,49.334761904761905,64.69666666666666,36.90309523809524,0,4,3,7,78.05928566620143,1
gpt-oss-120b-high,7,42,1630.0,1630.0,38.81047619047619,52.26142857142856,29.564047619047617,0,1,5,6,57.86813841578468,2
gemini-2.5-pro,7,42,1425.0,1425.0,33.92928571428571,56.7952380952381,18.651666666666667,0,1,4,5,56.439749486675154,3
gpt-oss-120b_sp2,7,42,1184.0,1184.0,28.191190476190474,44.05309523809524,23.015714285714285,0,0,5,5,49.73571806722164,4
gpt-oss-120b_sp4,7,42,1413.0,1413.0,33.64404761904762,47.23428571428571,22.620714285714286,0,0,4,4,55.820947931504456,5
gpt-oss-120b-medium,7,42,1270.0,1270.0,30.23857142857143,40.317619047619054,24.80238095238095,0,0,4,4,47.188769122601265,4
gpt-oss-20b-high,7,42,1215.0,1215.0,28.927142857142858,45.18214285714286,26.685476190476194,0,0,4,4,56.71161950722786,5
gpt-oss-120b_sp1,7,42,1201.0,1201.0,28.594761904761906,42.98619047619047,22.620714285714286,0,0,4,4,49.797081435036624,8
grok-4-fast-reasoning,7,42,1265.0,1265.0,30.118809523809524,57.889523809523816,18.847857142857144,0,1,2,3,43.593954486584416,9
gpt-oss-120b_sp3,7,42,1187.0,1187.0,28.261904761904763,41.138333333333335,22.817380952380955,0,1,2,3,47.292352508006026,10
gpt-o3-mini-high,7,42,1186.0,1186.0,28.237380952380953,48.27428571428571,18.651666666666667,0,0,3,3,50.558664479185076,6
gemini-2.5-flash,7,42,1161.0,1161.0,27.64404761904762,47.330238095238094,14.086428571428572,0,0,3,3,48.09842857102363,7
seed-oss_-1,7,42,955.0,955.0,22.738333333333333,44.60619047619046,14.285714285714285,0,0,3,3,39.640774254892115,8
seed-oss_16384,7,42,945.0,945.0,22.501190476190477,39.93119047619047,16.26904761904762,0,0,3,3,40.26622792706831,9
gpt-oss-20b-medium,7,42,961.0,961.0,22.88190476190476,37.13309523809523,20.23761904761905,0,0,2,2,37.62255398256607,10
claude-sonnet-4.5,7,42,931.0,931.0,22.166428571428572,54.64833333333333,7.142857142857142,0,0,2,2,39.84746354350832,16
Qwen3-32B,6,37,516.0,516.0,13.945405405405406,28.24513513513514,8.108108108108109,0,0,1,1,32.36932100596891,14
seed-oss_8192,7,42,803.0,803.0,19.119999999999997,35.74880952380953,11.904761904761903,0,0,1,1,33.172156968940115,11
gpt-oss-120b-low,7,42,755.0,755.0,17.97642857142857,31.22714285714285,13.889761904761905,0,0,1,1,29.01006317432594,12
deepseek-reasoner,7,42,649.0,649.0,15.453095238095237,28.77047619047619,9.523809523809524,0,0,1,1,21.415448915152087,13
Qwen3-30B,6,37,445.0,445.0,12.027837837837836,32.005675675675676,4.954054054054054,0,0,1,1,24.115897925172565,15
QwQ-32B,6,37,412.0,412.0,11.134594594594596,26.38837837837838,8.108108108108109,0,0,1,1,19.988548725853082,16
OlympicCoder-7B,7,42,356.0,356.0,8.477380952380953,16.48738095238095,7.34047619047619,0,0,1,1,12.95915333301296,23
Qwen3-8B,7,42,574.0,574.0,13.665952380952382,26.575238095238095,8.92690476190476,0,0,0,0,24.045731839911657,17
Qwen3-14B,6,37,53.0,53.0,1.4321621621621623,9.617837837837838,0.0,0,0,0,0,7.268317841129389,36
OpenCodeReasoning-Nemotron-32B-IOI,7,42,505.0,505.0,12.024285714285714,28.308571428571426,8.729761904761906,0,0,0,0,20.560466258703006,26
DeepSeek-R1-Distill-Llama-70B,7,42,426.0,426.0,10.141904761904764,22.805238095238092,7.142857142857142,0,0,0,0,12.513873745168102,18
gpt-oss-20b-low,7,42,386.0,386.0,9.190000000000001,19.78595238095238,7.142857142857142,0,0,0,0,14.090776187475011,19
gpt-4.1,7,42,377.0,377.0,8.97547619047619,31.364047619047625,2.380952380952381,0,0,0,0,13.058865276388778,20
deepseek-chat,6,37,343.0,343.0,9.27054054054054,27.149189189189194,2.7027027027027026,0,0,0,0,19.53497545925975,21
DeepSeek-R1-Distill-Qwen-32B,6,37,293.0,293.0,7.92054054054054,21.325135135135135,5.405405405405405,0,0,0,0,15.73421694820009,22
Qwen3-4B,7,42,283.0,283.0,6.739285714285715,17.923333333333336,4.761904761904762,0,0,0,0,8.175079072136686,23
seed-oss_4096,7,42,240.0,240.0,5.714047619047619,12.980714285714287,4.562619047619048,0,0,0,0,8.076595301407542,24
DeepSeek-R1-Distill-Qwen-14B,6,37,221.0,221.0,5.971891891891892,13.33054054054054,4.954054054054054,0,0,0,0,12.089286946712432,25
Qwen3-32B-Non-Thinking,7,42,56.0,56.0,1.3333333333333333,3.110714285714285,0.0,0,0,0,0,1.2048830165721012,35
seed-oss_2048,7,42,129.0,129.0,3.0714285714285716,8.697380952380952,2.380952380952381,0,0,0,0,7.0675146894075285,26
Codestral-22B-v0.1,6,37,119.0,119.0,3.217027027027027,8.775945945945947,2.2513513513513512,0,0,0,0,8.718595652281907,27
seed-oss_0,7,42,109.0,109.0,2.5961904761904764,7.9088095238095235,2.380952380952381,0,0,0,0,4.83680145363859,28
Qwen2.5-Coder-32B-Instruct,6,37,109.0,109.0,2.9454054054054053,13.572702702702705,0.0,0,0,0,0,5.065422034513484,29
Llama-4-Scout,7,42,77.0,77.0,1.8347619047619048,11.040238095238095,0.0,0,0,0,0,2.335581141493975,31
Qwen3-8B-Non-Thinking,7,42,32.0,32.0,0.7619047619047619,4.103571428571429,0.0,0,0,0,0,0.7831645136727865,39
Mistral-Large-Instruct-2411,7,42,80.0,80.0,1.9047619047619047,14.17,0.0,0,0,0,0,2.9889722958077334,30
Llama-3.3-70B-Instruct,6,37,74.0,74.0,2.0013513513513512,13.647567567567567,0.0,0,0,0,0,5.908797150312002,33
Qwen3-4B-Non-Thinking,7,42,72.0,72.0,1.7130952380952382,8.362142857142857,0.0,0,0,0,0,1.9497469857017093,34
Qwen3-30B-Non-Thinking,7,42,76.0,76.0,1.8088095238095239,11.701666666666666,0.0,0,0,0,0,2.411203485219848,32
Qwen2.5-Coder-14B-Instruct,6,37,51.0,51.0,1.3786486486486487,14.567297297297296,0.0,0,0,0,0,2.246147100931101,37
Qwen3-14B-Non-Thinking,7,42,26.0,26.0,0.6178571428571429,6.317380952380954,0.0,0,0,0,0,3.7943259016190294,43
Qwen2.5-72B,6,37,46.0,46.0,1.241891891891892,11.063783783783784,0.0,0,0,0,0,2.609890432809759,38
Qwen2.5-Coder-7B-Instruct,7,42,28.0,28.0,0.6666666666666666,6.8999999999999995,0.0,0,0,0,0,0.45844144161831035,41
seed-oss_1024,7,42,27.0,27.0,0.6438095238095238,6.066666666666666,0.0,0,0,0,0,1.2006805539784509,42
DeepSeek-Coder-V2-Lite-Instruct,6,37,29.0,29.0,0.7824324324324324,8.367837837837836,0.0,0,0,0,0,1.2286501271552412,40
seed-oss_512,7,42,12.0,12.0,0.2857142857142857,5.1795238095238085,0.0,0,0,0,0,0.30332007473643874,44
Mistral-Small-3.1-24B-2503,6,37,8.0,8.0,0.21621621621621623,5.604864864864865,0.0,0,0,0,0,0.879405875471965,45
DeepSeek-R1-Distill-Llama-8B,6,37,3.0,3.0,0.08108108108108109,1.622972972972973,0.0,0,0,0,0,0.41816009557945044,46
DeepSeek-R1-Distill-Qwen-7B,6,37,0.0,0.0,0.0,0.5635135135135136,0.0,0,0,0,0,0.2986857825567503,47
Llama-3.1-8B-Instruct,6,37,0.0,0.0,0.0,3.054054054054054,0.0,0,0,0,0,0.2986857825567503,48
