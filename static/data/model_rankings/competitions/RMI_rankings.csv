Model,Contest Count,Total Tasks,Total Score,Total Included Score,Relative Score (%),Avg Tests Passed (%),Pass Rate (%),Gold Medals,Silver Medals,Bronze Medals,Total Medals,Avg Human Percentile,Competition Rank
gpt-5,2,12,878.0,878.0,73.17,81.42,58.335,2,0,0,2,98.49769397721107,1
grok-4-fast-reasoning,2,12,683.0,683.0,56.915,73.245,33.335,2,0,0,2,93.61774281063484,2
gpt-oss-120b-high,2,12,689.0,689.0,57.415,67.04500000000002,50.0,1,1,0,2,90.62330439500815,2
gpt-oss-120b_sp3,2,12,440.0,440.0,36.669999999999995,53.074999999999996,25.0,0,2,0,2,77.87574606619643,4
gemini-2.5-pro,2,12,404.0,404.0,33.67,49.97,16.669999999999998,0,1,1,2,72.32094411285948,3
gpt-oss-120b_sp4,2,12,440.0,440.0,36.665,44.449999999999996,33.33,0,1,1,2,79.18136190992946,6
gpt-oss-120b_sp2,2,12,394.0,394.0,32.835,50.42,16.669999999999998,0,1,1,2,73.84698860553445,7
gpt-oss-120b_sp1,2,12,378.0,378.0,31.5,41.54,25.0,0,1,1,2,67.75298426478568,8
gemini-2.5-flash,2,12,403.0,403.0,33.585,52.16,16.669999999999998,0,1,1,2,74.01654910472057,4
seed-oss_-1,2,12,355.0,355.0,29.58,44.55500000000001,16.669999999999998,0,1,1,2,69.59780249593055,5
gpt-oss-120b-low,2,12,350.0,350.0,29.165000000000003,43.67,16.669999999999998,0,1,1,2,68.75339120998373,6
gpt-o3-mini-high,2,12,403.0,403.0,33.585,50.135000000000005,16.665,0,0,2,2,72.22259902333153,7
gpt-oss-120b-medium,2,12,388.0,388.0,32.335,44.92,25.0,0,0,2,2,69.38754747693977,8
claude-sonnet-4.5,2,12,309.0,309.0,25.75,53.080000000000005,8.334999999999999,0,0,2,2,61.136733586543684,14
gpt-oss-20b-medium,2,12,303.0,303.0,25.25,40.24000000000001,18.335,0,0,2,2,59.20035268583831,9
gpt-oss-20b-high,2,12,342.0,342.0,28.5,53.074999999999996,20.000000000000004,0,1,0,1,53.63198589256647,10
seed-oss_16384,2,12,304.0,304.0,25.33,45.27,8.334999999999999,0,1,0,1,62.83233857840477,11
DeepSeek-R1-Distill-Llama-70B,2,12,179.0,179.0,14.915,20.125,8.334999999999999,0,1,0,1,40.56226261530114,12
seed-oss_8192,2,12,215.0,215.0,17.92,30.61,8.334999999999999,0,0,1,1,44.55710797612588,13
gpt-oss-20b-low,2,12,182.0,182.0,15.170000000000002,30.255000000000003,8.334999999999999,0,0,1,1,39.56185567010309,14
seed-oss_4096,2,12,128.0,128.0,10.665,18.725,8.334999999999999,0,0,1,1,30.252984264785677,15
Mistral-Small-3.1-24B-2503,2,12,113.0,113.0,9.415,15.47,8.334999999999999,0,0,1,1,28.191128594682585,16
Mistral-Large-Instruct-2411,2,12,107.0,107.0,8.915,13.114999999999998,8.334999999999999,0,0,1,1,27.16020075963104,17
Qwen2.5-Coder-14B-Instruct,2,12,107.0,107.0,8.915,11.435,8.334999999999999,0,0,1,1,27.16020075963104,18
seed-oss_2048,2,12,107.0,107.0,8.915,14.87,8.334999999999999,0,0,1,1,27.16020075963104,19
deepseek-reasoner,2,12,170.0,170.0,14.165000000000001,31.81,0.0,0,0,0,0,38.1578947368421,20
Qwen3-32B,2,12,163.0,163.0,13.584999999999999,35.754999999999995,0.0,0,0,0,0,35.821351058057516,21
gpt-4.1,2,12,58.0,58.0,4.835,16.014999999999997,0.0,0,0,0,0,17.65124796527401,28
OlympicCoder-7B,2,12,111.0,111.0,9.250000000000002,17.900000000000002,8.334999999999999,0,0,0,0,28.289473684210527,29
seed-oss_0,2,12,106.0,106.0,8.835,12.989999999999998,8.334999999999999,0,0,0,0,26.644736842105264,22
Qwen3-8B,2,12,104.0,104.0,8.67,18.775,0.0,0,0,0,0,26.644736842105264,23
Qwen3-30B,2,12,41.0,41.0,3.4150000000000005,10.100000000000001,0.0,0,0,0,0,14.78906673901248,30
seed-oss_512,2,12,100.0,100.0,8.335,9.000000000000002,8.334999999999999,0,0,0,0,26.644736842105264,24
seed-oss_1024,2,12,100.0,100.0,8.335,12.059999999999999,8.334999999999999,0,0,0,0,26.644736842105264,25
Llama-4-Scout,2,12,100.0,100.0,8.335,12.345,8.334999999999999,0,0,0,0,26.644736842105264,26
Qwen3-8B-Non-Thinking,2,12,0.0,0.0,0.0,0.0,0.0,0,0,0,0,3.964324470971243,42
Qwen3-14B,2,12,68.0,68.0,5.665,12.605000000000002,0.0,0,0,0,0,19.94370591427021,27
OpenCodeReasoning-Nemotron-32B-IOI,2,12,75.0,75.0,6.25,20.16,0.0,0,0,0,0,18.76356483993489,38
Llama-3.3-70B-Instruct,2,12,57.0,57.0,4.75,15.55,0.0,0,0,0,0,18.139582202930004,29
DeepSeek-R1-Distill-Qwen-32B,2,12,37.0,37.0,3.0849999999999995,8.285,0.0,0,0,0,0,10.692485078676071,32
Qwen3-14B-Non-Thinking,2,12,0.0,0.0,0.0,0.0,0.0,0,0,0,0,3.964324470971243,43
Qwen2.5-72B,2,12,20.0,20.0,1.665,6.635000000000001,0.0,0,0,0,0,6.799376017362995,36
Llama-3.1-8B-Instruct,2,12,39.0,39.0,3.25,7.28,0.0,0,0,0,0,14.01587086272382,31
deepseek-chat,2,12,37.0,37.0,3.0849999999999995,17.49,0.0,0,0,0,0,9.244438415626696,33
QwQ-32B,2,12,8.0,8.0,0.665,6.915,0.0,0,0,0,0,3.964324470971243,40
Codestral-22B-v0.1,2,12,32.0,32.0,2.665,1.6549999999999998,0.0,0,0,0,0,11.180819316332068,34
Qwen3-32B-Non-Thinking,2,12,30.0,30.0,2.5,13.43,0.0,0,0,0,0,10.665355398806295,35
Qwen2.5-Coder-32B-Instruct,2,12,20.0,20.0,1.665,10.315000000000001,0.0,0,0,0,0,6.799376017362995,37
Qwen3-4B,2,12,13.0,13.0,1.085,10.45,0.0,0,0,0,0,5.768448182311448,38
DeepSeek-Coder-V2-Lite-Instruct,2,12,11.0,11.0,0.915,6.509999999999999,0.0,0,0,0,0,6.026180141074335,39
Qwen3-30B-Non-Thinking,2,12,2.0,2.0,0.165,4.305,0.0,0,0,0,0,3.964324470971243,41
Qwen3-4B-Non-Thinking,2,12,0.0,0.0,0.0,0.0,0.0,0,0,0,0,3.964324470971243,46
DeepSeek-R1-Distill-Qwen-7B,2,12,0.0,0.0,0.0,0.0,0.0,0,0,0,0,3.964324470971243,44
DeepSeek-R1-Distill-Llama-8B,2,12,0.0,0.0,0.0,0.0,0.0,0,0,0,0,3.964324470971243,45
Qwen2.5-Coder-7B-Instruct,2,12,0.0,0.0,0.0,1.19,0.0,0,0,0,0,3.964324470971243,47
DeepSeek-R1-Distill-Qwen-14B,2,12,0.0,0.0,0.0,4.355,0.0,0,0,0,0,3.964324470971243,48
