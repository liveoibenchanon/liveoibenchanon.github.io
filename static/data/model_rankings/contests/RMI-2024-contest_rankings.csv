Model,Total Score,Included Tasks,Included Score,Avg Tests Passed,Pass Rate (%),Medal,Human Relative Rank,Human Percentile,Rank,Relative Score (%)
gpt-5,361.0,6,361.0,70.44,50.0,Gold,3,98.96907216494846,1,60.17
grok-4-fast-reasoning,273.0,6,273.0,62.72,16.67,Gold,13,93.81443298969072,2,45.5
gpt-oss-120b-high,230.0,6,230.0,47.96,33.33,Silver,31,84.5360824742268,2,38.33
gpt-oss-120b_sp2,213.0,6,213.0,52.01,16.67,Silver,31,84.5360824742268,4,35.5
gpt-oss-120b_sp4,200.0,6,200.0,36.51,33.33,Silver,32,84.02061855670104,5,33.33
seed-oss_-1,194.0,6,194.0,48.16,16.67,Silver,36,81.95876288659794,3,32.33
seed-oss_16384,191.0,6,191.0,44.42,16.67,Silver,38,80.9278350515464,4,31.83
gpt-oss-120b-low,191.0,6,191.0,43.77,16.67,Silver,38,80.9278350515464,5,31.83
gemini-2.5-flash,189.0,6,189.0,47.53,16.67,Silver,38,80.9278350515464,6,31.5
DeepSeek-R1-Distill-Llama-70B,179.0,6,179.0,40.25,16.67,Silver,44,77.83505154639175,7,29.83
gpt-oss-120b_sp3,175.0,6,175.0,44.35,16.67,Silver,46,76.80412371134021,11,29.17
gpt-o3-mini-high,163.0,6,163.0,47.6,0.0,Bronze,59,70.10309278350516,8,27.17
claude-sonnet-4.5,155.0,6,155.0,49.18,16.67,Bronze,65,67.01030927835052,13,25.83
gemini-2.5-pro,154.0,6,154.0,41.05,16.67,Bronze,65,67.01030927835052,9,25.67
gpt-oss-120b-medium,148.0,6,148.0,37.45,16.67,Bronze,70,64.43298969072166,10,24.67
seed-oss_8192,139.0,6,139.0,31.79,16.67,Bronze,77,60.824742268041234,11,23.17
gpt-oss-20b-medium,128.0,6,128.0,34.46,20.0,Bronze,84,57.21649484536083,12,21.33
seed-oss_4096,128.0,6,128.0,30.72,16.67,Bronze,84,57.21649484536083,13,21.33
gpt-oss-120b_sp1,127.0,6,127.0,29.85,16.67,Bronze,84,57.21649484536083,19,21.17
gpt-oss-20b-low,118.0,6,118.0,38.73,16.67,Bronze,90,54.123711340206185,14,19.67
Mistral-Small-3.1-24B-2503,113.0,6,113.0,28.61,16.67,Bronze,92,53.09278350515464,15,18.83
Mistral-Large-Instruct-2411,107.0,6,107.0,26.23,16.67,Bronze,96,51.03092783505155,16,17.83
Qwen2.5-Coder-14B-Instruct,107.0,6,107.0,22.87,16.67,Bronze,96,51.03092783505155,17,17.83
seed-oss_2048,107.0,6,107.0,26.88,16.67,Bronze,96,51.03092783505155,18,17.83
deepseek-reasoner,102.0,6,102.0,31.54,0.0,None,98,50.0,19,17.0
seed-oss_512,100.0,6,100.0,16.67,16.67,None,98,50.0,20,16.67
seed-oss_0,100.0,6,100.0,17.65,16.67,None,98,50.0,21,16.67
seed-oss_1024,100.0,6,100.0,20.95,16.67,None,98,50.0,22,16.67
OlympicCoder-7B,100.0,6,100.0,20.03,16.67,None,98,50.0,29,16.67
Llama-4-Scout,100.0,6,100.0,24.69,16.67,None,98,50.0,23,16.67
Qwen3-8B,100.0,6,100.0,26.22,0.0,None,98,50.0,24,16.67
Qwen3-32B,78.0,6,78.0,31.78,0.0,None,116,40.72164948453608,25,13.0
Qwen3-8B-Non-Thinking,0.0,6,0.0,0.0,0.0,None,186,4.639175257731959,42,0.0
Qwen3-14B,68.0,6,68.0,24.42,0.0,None,124,36.597938144329895,26,11.33
Llama-3.3-70B-Instruct,57.0,6,57.0,30.31,0.0,None,131,32.98969072164948,27,9.5
gpt-4.1,49.0,6,49.0,24.94,0.0,None,138,29.38144329896907,28,8.17
Qwen3-14B-Non-Thinking,0.0,6,0.0,0.0,0.0,None,186,4.639175257731959,43,0.0
Qwen3-30B,41.0,6,41.0,19.41,0.0,None,144,26.288659793814432,29,6.83
Llama-3.1-8B-Instruct,39.0,6,39.0,14.56,0.0,None,147,24.742268041237114,30,6.5
OpenCodeReasoning-Nemotron-32B-IOI,38.0,6,38.0,23.29,0.0,None,149,23.711340206185568,40,6.33
gpt-oss-20b-high,38.0,6,38.0,31.29,0.0,None,149,23.711340206185568,31,6.33
Codestral-22B-v0.1,32.0,6,32.0,3.31,0.0,None,158,19.072164948453608,32,5.33
Qwen3-32B-Non-Thinking,30.0,6,30.0,17.07,0.0,None,160,18.04123711340206,33,5.0
DeepSeek-R1-Distill-Qwen-32B,28.0,6,28.0,10.79,0.0,None,165,15.463917525773196,34,4.67
Qwen2.5-72B,20.0,6,20.0,10.24,0.0,None,175,10.309278350515465,35,3.33
Qwen2.5-Coder-32B-Instruct,20.0,6,20.0,17.6,0.0,None,175,10.309278350515465,36,3.33
deepseek-chat,15.0,6,15.0,19.05,0.0,None,177,9.278350515463918,37,2.5
DeepSeek-Coder-V2-Lite-Instruct,11.0,6,11.0,11.69,0.0,None,178,8.762886597938145,38,1.83
Qwen3-4B,9.0,6,9.0,12.66,0.0,None,179,8.24742268041237,39,1.5
QwQ-32B,2.0,6,2.0,9.43,0.0,None,186,4.639175257731959,40,0.33
Qwen3-30B-Non-Thinking,2.0,6,2.0,4.79,0.0,None,186,4.639175257731959,41,0.33
DeepSeek-R1-Distill-Qwen-7B,0.0,6,0.0,0.0,0.0,None,186,4.639175257731959,44,0.0
DeepSeek-R1-Distill-Llama-8B,0.0,6,0.0,0.0,0.0,None,186,4.639175257731959,45,0.0
Qwen2.5-Coder-7B-Instruct,0.0,6,0.0,2.38,0.0,None,186,4.639175257731959,47,0.0
Qwen3-4B-Non-Thinking,0.0,6,0.0,0.0,0.0,None,186,4.639175257731959,46,0.0
DeepSeek-R1-Distill-Qwen-14B,0.0,6,0.0,8.71,0.0,None,186,4.639175257731959,48,0.0
