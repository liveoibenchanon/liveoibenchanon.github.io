Model,Total Score,Included Tasks,Included Score,Avg Tests Passed,Pass Rate (%),Medal,Human Relative Rank,Human Percentile,Rank,Relative Score (%)
grok-4-fast-reasoning,450.0,5,450.0,100.0,100.0,Gold,1,100.0,1,90.0
gpt-5,450.0,5,450.0,100.0,100.0,Gold,1,100.0,1,90.0
gpt-oss-120b-high,404.0,5,404.0,98.42,80.0,Gold,13,94.97907949790795,2,80.8
gpt-oss-120b_sp4,404.0,5,404.0,96.84,80.0,Gold,13,94.97907949790795,4,80.8
gpt-oss-120b-medium,404.0,5,404.0,91.58,80.0,Gold,13,94.97907949790795,5,80.8
gemini-2.5-flash,404.0,5,404.0,91.58,80.0,Gold,13,94.97907949790795,3,80.8
gemini-2.5-pro,404.0,5,404.0,91.58,80.0,Gold,13,94.97907949790795,4,80.8
gpt-oss-120b_sp3,369.0,5,369.0,85.26,80.0,Silver,36,85.35564853556485,8,73.8
gpt-oss-120b_sp1,369.0,5,369.0,85.26,80.0,Silver,36,85.35564853556485,9,73.8
gpt-oss-120b_sp2,369.0,5,369.0,85.26,80.0,Silver,36,85.35564853556485,10,73.8
seed-oss_16384,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,9,68.0
gpt-oss-20b-medium,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,7,68.0
seed-oss_-1,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,6,68.0
gpt-oss-20b-high,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,8,68.0
QwQ-32B,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,13,68.0
gpt-oss-120b-low,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,10,68.0
gpt-o3-mini-high,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,12,68.0
deepseek-reasoner,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,11,68.0
OpenCodeReasoning-Nemotron-32B-IOI,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,19,68.0
gpt-4.1,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,14,68.0
Qwen3-30B,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,15,68.0
seed-oss_8192,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,16,68.0
Qwen3-32B,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,17,68.0
Qwen3-14B,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,19,68.0
Qwen3-8B,340.0,5,340.0,80.0,80.0,Silver,41,83.26359832635983,18,68.0
seed-oss_4096,273.0,5,273.0,68.92,60.0,Bronze,67,72.38493723849372,20,54.6
deepseek-chat,250.0,5,250.0,65.0,60.0,Bronze,73,69.8744769874477,21,50.0
gpt-oss-20b-low,230.0,5,230.0,62.43,60.0,Bronze,77,68.20083682008368,22,46.0
DeepSeek-R1-Distill-Llama-70B,230.0,5,230.0,62.16,60.0,Bronze,77,68.20083682008368,23,46.0
OlympicCoder-7B,230.0,5,230.0,61.89,60.0,Bronze,77,68.20083682008368,30,46.0
claude-sonnet-4.5,210.0,5,210.0,72.24,40.0,Bronze,92,61.92468619246862,31,42.0
Qwen3-4B,140.0,5,140.0,53.64,40.0,None,125,48.11715481171548,24,28.0
DeepSeek-R1-Distill-Qwen-32B,130.0,5,130.0,48.5,40.0,None,125,48.11715481171548,25,26.0
Mistral-Small-3.1-24B-2503,130.0,5,130.0,49.58,40.0,None,125,48.11715481171548,26,26.0
Qwen3-32B-Non-Thinking,130.0,5,130.0,49.31,40.0,None,125,48.11715481171548,27,26.0
Llama-4-Scout,130.0,5,130.0,49.58,40.0,None,125,48.11715481171548,29,26.0
Mistral-Large-Instruct-2411,130.0,5,130.0,52.01,40.0,None,125,48.11715481171548,28,26.0
Qwen3-8B-Non-Thinking,130.0,5,130.0,49.04,40.0,None,125,48.11715481171548,30,26.0
Llama-3.3-70B-Instruct,130.0,5,130.0,50.93,40.0,None,125,48.11715481171548,31,26.0
Qwen2.5-72B,130.0,5,130.0,50.43,40.0,None,125,48.11715481171548,32,26.0
Qwen2.5-Coder-14B-Instruct,130.0,5,130.0,49.58,40.0,None,125,48.11715481171548,33,26.0
Codestral-22B-v0.1,123.0,5,123.0,46.94,20.0,None,129,46.44351464435147,34,24.6
seed-oss_1024,120.0,5,120.0,42.16,40.0,None,129,46.44351464435147,35,24.0
seed-oss_0,120.0,5,120.0,40.27,40.0,None,129,46.44351464435147,36,24.0
seed-oss_2048,120.0,5,120.0,41.62,40.0,None,129,46.44351464435147,37,24.0
seed-oss_512,120.0,5,120.0,41.62,40.0,None,129,46.44351464435147,38,24.0
DeepSeek-R1-Distill-Qwen-14B,80.0,5,80.0,28.5,20.0,None,184,23.430962343096233,40,16.0
Qwen3-30B-Non-Thinking,80.0,5,80.0,29.36,20.0,None,184,23.430962343096233,39,16.0
DeepSeek-Coder-V2-Lite-Instruct,70.0,5,70.0,24.44,20.0,None,188,21.757322175732217,41,14.0
Qwen3-4B-Non-Thinking,37.0,5,37.0,30.65,0.0,None,226,5.857740585774058,42,7.4
Qwen2.5-Coder-32B-Instruct,33.0,5,33.0,19.5,0.0,None,226,5.857740585774058,43,6.6
Qwen2.5-Coder-7B-Instruct,16.0,5,16.0,7.01,0.0,None,227,5.439330543933054,44,3.2
DeepSeek-R1-Distill-Llama-8B,0.0,5,0.0,0.0,0.0,None,231,3.7656903765690375,45,0.0
Qwen3-14B-Non-Thinking,0.0,5,0.0,5.32,0.0,None,231,3.7656903765690375,46,0.0
Llama-3.1-8B-Instruct,0.0,5,0.0,7.5,0.0,None,231,3.7656903765690375,47,0.0
