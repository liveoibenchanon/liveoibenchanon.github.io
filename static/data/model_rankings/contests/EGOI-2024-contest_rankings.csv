Model,Total Score,Included Tasks,Included Score,Avg Tests Passed,Pass Rate (%),Medal,Human Relative Rank,Human Percentile,Rank,Relative Score (%)
gpt-5,600.0,6,600.0,75.0,75.0,Gold,1,100.0,1,100.0
grok-4-fast-reasoning,459.0,6,459.0,84.06,66.67,Gold,13,93.84615384615384,2,76.5
gpt-oss-120b-high,436.0,6,436.0,59.69,50.0,Gold,22,89.23076923076923,2,72.67
gpt-oss-120b_sp4,411.0,6,411.0,52.69,50.0,Silver,29,85.64102564102564,4,68.5
gemini-2.5-pro,364.0,6,364.0,55.27,37.5,Silver,55,72.3076923076923,3,60.67
gpt-oss-120b-medium,348.0,6,348.0,53.1,37.5,Silver,63,68.2051282051282,4,58.0
gpt-oss-120b_sp1,337.0,6,337.0,53.29,37.5,Bronze,66,66.66666666666667,7,56.17
gpt-oss-20b-medium,436.0,6,336.0,63.85,50.0,Bronze,69,65.12820512820512,5,56.0
gpt-o3-mini-high,336.0,6,336.0,51.76,37.5,Bronze,69,65.12820512820512,6,56.0
gpt-oss-120b_sp2,325.0,6,325.0,49.35,37.5,Bronze,73,63.07692307692308,10,54.17
gpt-oss-120b_sp3,362.0,6,262.0,61.66,37.5,None,104,47.17948717948718,11,43.67
claude-sonnet-4.5,244.0,6,244.0,61.78,16.67,None,115,41.53846153846154,12,40.67
seed-oss_16384,235.0,6,235.0,42.23,25.0,None,116,41.02564102564103,7,39.17
seed-oss_-1,225.0,6,225.0,41.4,25.0,None,117,40.51282051282051,8,37.5
gpt-oss-20b-high,200.0,6,200.0,40.0,40.0,None,128,34.87179487179487,9,33.33
gemini-2.5-flash,191.0,6,191.0,38.74,12.5,None,131,33.333333333333336,10,31.83
gpt-oss-20b-low,272.0,6,172.0,43.14,25.0,None,140,28.71794871794872,11,28.67
deepseek-reasoner,171.0,6,171.0,36.01,12.5,None,140,28.71794871794872,12,28.5
OpenCodeReasoning-Nemotron-32B-IOI,125.0,6,125.0,30.47,12.5,None,163,16.923076923076923,19,20.83
seed-oss_8192,124.0,6,124.0,27.42,12.5,None,163,16.923076923076923,13,20.67
gpt-oss-120b-low,95.0,6,95.0,33.72,0.0,None,172,12.307692307692308,14,15.83
deepseek-chat,81.0,6,81.0,29.72,0.0,None,177,9.743589743589743,15,13.5
Qwen3-32B,81.0,6,81.0,32.41,0.0,None,177,9.743589743589743,16,13.5
Qwen2.5-72B,72.0,6,72.0,22.3,0.0,None,182,7.17948717948718,17,12.0
Qwen3-14B,57.0,6,57.0,29.78,0.0,None,188,4.102564102564102,18,9.5
seed-oss_4096,56.0,6,56.0,15.5,0.0,None,188,4.102564102564102,20,9.33
Llama-3.3-70B-Instruct,56.0,6,56.0,17.97,0.0,None,188,4.102564102564102,19,9.33
DeepSeek-R1-Distill-Llama-70B,54.0,6,54.0,25.35,0.0,None,188,4.102564102564102,21,9.0
Qwen3-30B,51.0,6,51.0,27.83,0.0,None,189,3.58974358974359,23,8.5
gpt-4.1,39.0,6,39.0,23.14,0.0,None,191,2.5641025641025643,25,6.5
Qwen3-30B-Non-Thinking,36.0,6,36.0,23.32,0.0,None,191,2.5641025641025643,27,6.0
Qwen3-8B,32.0,6,32.0,23.46,0.0,None,191,2.5641025641025643,28,5.33
Qwen3-4B,32.0,6,32.0,23.67,0.0,None,191,2.5641025641025643,29,5.33
Llama-4-Scout,28.0,6,28.0,20.54,0.0,None,193,1.5384615384615385,30,4.67
OlympicCoder-7B,26.0,6,26.0,15.87,0.0,None,193,1.5384615384615385,35,4.33
Qwen3-32B-Non-Thinking,0.0,6,0.0,0.0,0.0,None,194,1.0256410256410255,44,0.0
Qwen3-4B-Non-Thinking,20.0,6,20.0,16.55,0.0,None,193,1.5384615384615385,31,3.33
Qwen3-14B-Non-Thinking,20.0,6,20.0,14.5,0.0,None,193,1.5384615384615385,32,3.33
Qwen3-8B-Non-Thinking,20.0,6,20.0,20.28,0.0,None,193,1.5384615384615385,33,3.33
DeepSeek-Coder-V2-Lite-Instruct,16.0,6,16.0,8.87,0.0,None,194,1.0256410256410255,35,2.67
seed-oss_0,16.0,6,16.0,13.86,0.0,None,194,1.0256410256410255,37,2.67
Qwen2.5-Coder-14B-Instruct,16.0,6,16.0,14.41,0.0,None,194,1.0256410256410255,36,2.67
Mistral-Large-Instruct-2411,16.0,6,16.0,14.42,0.0,None,194,1.0256410256410255,34,2.67
DeepSeek-R1-Distill-Llama-8B,14.0,6,14.0,5.27,0.0,None,194,1.0256410256410255,39,2.33
seed-oss_1024,14.0,6,14.0,7.45,0.0,None,194,1.0256410256410255,40,2.33
seed-oss_2048,12.0,6,12.0,9.48,0.0,None,194,1.0256410256410255,42,2.0
seed-oss_512,12.0,6,12.0,10.37,0.0,None,194,1.0256410256410255,41,2.0
QwQ-32B,49.0,6,49.0,24.0,0.0,None,189,3.58974358974359,24,8.17
DeepSeek-R1-Distill-Qwen-32B,52.0,6,52.0,29.92,0.0,None,189,3.58974358974359,22,8.67
Llama-3.1-8B-Instruct,100.0,6,0.0,15.23,12.5,None,194,1.0256410256410255,43,0.0
DeepSeek-R1-Distill-Qwen-7B,0.0,6,0.0,0.0,0.0,None,194,1.0256410256410255,45,0.0
Qwen2.5-Coder-32B-Instruct,36.0,6,36.0,20.68,0.0,None,191,2.5641025641025643,26,6.0
DeepSeek-R1-Distill-Qwen-14B,14.0,6,14.0,13.48,0.0,None,194,1.0256410256410255,38,2.33
Codestral-22B-v0.1,0.0,6,0.0,3.27,0.0,None,194,1.0256410256410255,46,0.0
Qwen2.5-Coder-7B-Instruct,0.0,6,0.0,6.5,0.0,None,194,1.0256410256410255,47,0.0
Mistral-Small-3.1-24B-2503,0.0,6,0.0,6.67,0.0,None,194,1.0256410256410255,48,0.0
