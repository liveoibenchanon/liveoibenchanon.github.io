Model,Total Score,Included Tasks,Included Score,Avg Tests Passed,Pass Rate (%),Medal,Human Relative Rank,Human Percentile,Rank,Relative Score (%)
grok-4-fast-reasoning,382.0,5,382.0,97.07,80.0,Gold,2,99.67105263157895,1,76.4
gpt-oss-120b-high,340.0,5,340.0,80.0,80.0,Gold,9,97.36842105263158,1,68.0
claude-sonnet-4.5,305.0,5,305.0,80.67,60.0,Gold,18,94.40789473684211,3,61.0
OpenCodeReasoning-Nemotron-32B-IOI,285.0,5,285.0,74.67,60.0,Gold,19,94.07894736842105,4,57.0
gpt-5,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,2,52.0
Qwen3-32B,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,7,52.0
Qwen3-14B,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,8,52.0
Qwen3-30B,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,10,52.0
gemini-2.5-pro,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,4,52.0
seed-oss_16384,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,11,52.0
deepseek-reasoner,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,6,52.0
gemini-2.5-flash,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,3,52.0
seed-oss_-1,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,12,52.0
gpt-4.1,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,9,52.0
gpt-o3-mini-high,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,5,52.0
Qwen3-8B,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,13,52.0
Qwen3-4B,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,14,52.0
OlympicCoder-7B,260.0,5,260.0,74.02,60.0,Silver,35,88.8157894736842,18,52.0
gpt-oss-20b-high,230.0,5,230.0,100.0,100.0,Silver,49,84.21052631578948,15,46.0
gpt-oss-120b_sp3,230.0,5,230.0,62.67,60.0,Silver,49,84.21052631578948,20,46.0
gpt-oss-120b_sp2,230.0,5,230.0,62.67,60.0,Silver,49,84.21052631578948,21,46.0
seed-oss_8192,230.0,5,230.0,62.67,60.0,Silver,49,84.21052631578948,16,46.0
seed-oss_4096,230.0,5,230.0,62.67,60.0,Silver,49,84.21052631578948,18,46.0
gpt-oss-120b_sp4,230.0,5,230.0,62.81,60.0,Silver,49,84.21052631578948,24,46.0
gpt-oss-20b-medium,230.0,5,230.0,62.67,60.0,Silver,49,84.21052631578948,19,46.0
gpt-oss-20b-low,230.0,5,230.0,62.67,60.0,Silver,49,84.21052631578948,17,46.0
gpt-oss-120b_sp1,230.0,5,230.0,62.67,60.0,Silver,49,84.21052631578948,27,46.0
gpt-oss-120b-medium,230.0,5,230.0,62.74,60.0,Silver,49,84.21052631578948,22,46.0
QwQ-32B,230.0,5,230.0,62.67,60.0,Silver,49,84.21052631578948,21,46.0
gpt-oss-120b-low,230.0,5,230.0,62.67,60.0,Silver,49,84.21052631578948,20,46.0
seed-oss_1024,230.0,5,230.0,60.0,60.0,Silver,49,84.21052631578948,23,46.0
DeepSeek-R1-Distill-Qwen-32B,230.0,5,230.0,62.67,60.0,Silver,49,84.21052631578948,24,46.0
DeepSeek-R1-Distill-Llama-70B,230.0,5,230.0,62.67,60.0,Silver,49,84.21052631578948,25,46.0
seed-oss_2048,230.0,5,230.0,62.67,60.0,Silver,49,84.21052631578948,26,46.0
deepseek-chat,214.0,5,214.0,61.52,40.0,Silver,71,76.97368421052632,27,42.8
Qwen3-32B-Non-Thinking,210.0,5,210.0,63.16,40.0,Silver,71,76.97368421052632,28,42.0
Qwen3-30B-Non-Thinking,180.0,5,180.0,52.38,40.0,Bronze,86,72.03947368421052,29,36.0
Qwen2.5-Coder-32B-Instruct,180.0,5,180.0,51.81,40.0,Bronze,86,72.03947368421052,30,36.0
DeepSeek-R1-Distill-Qwen-14B,180.0,5,180.0,48.95,40.0,Bronze,86,72.03947368421052,31,36.0
Mistral-Large-Instruct-2411,133.0,5,133.0,56.19,20.0,Bronze,128,58.223684210526315,32,26.6
seed-oss_0,132.0,5,132.0,44.83,40.0,Bronze,131,57.23684210526316,33,26.4
Llama-4-Scout,109.0,5,109.0,48.02,20.0,None,161,47.36842105263158,34,21.8
Llama-3.3-70B-Instruct,54.0,5,54.0,28.0,0.0,None,226,25.986842105263158,35,10.8
Qwen3-4B-Non-Thinking,29.0,5,29.0,16.67,0.0,None,284,6.907894736842105,37,5.8
Qwen2.5-Coder-7B-Instruct,29.0,5,29.0,25.81,0.0,None,284,6.907894736842105,38,5.8
Mistral-Small-3.1-24B-2503,29.0,5,29.0,26.48,0.0,None,284,6.907894736842105,39,5.8
Qwen2.5-72B,29.0,5,29.0,21.9,0.0,None,284,6.907894736842105,40,5.8
Qwen3-8B-Non-Thinking,29.0,5,29.0,19.33,0.0,None,284,6.907894736842105,41,5.8
DeepSeek-Coder-V2-Lite-Instruct,29.0,5,29.0,26.48,0.0,None,284,6.907894736842105,36,5.8
Qwen3-14B-Non-Thinking,29.0,5,29.0,25.81,0.0,None,284,6.907894736842105,42,5.8
Qwen2.5-Coder-14B-Instruct,0.0,5,0.0,0.0,0.0,None,297,2.6315789473684212,44,0.0
seed-oss_512,0.0,5,0.0,0.0,0.0,None,297,2.6315789473684212,43,0.0
Llama-3.1-8B-Instruct,0.0,5,0.0,9.14,0.0,None,297,2.6315789473684212,46,0.0
DeepSeek-R1-Distill-Llama-8B,0.0,5,0.0,0.0,0.0,None,297,2.6315789473684212,45,0.0
Codestral-22B-v0.1,0.0,5,0.0,10.64,0.0,None,297,2.6315789473684212,47,0.0
